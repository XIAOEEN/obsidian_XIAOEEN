
### Main Method:

EverTracer detects ***whether a suspect model retains latent memorization of proprietary fingerprint data***, enabling robust and stealthy provenance tracing at inference time.

#### 核心创新点
EverTracer 是**首个将成员推断攻击（MIA）用于防御性用途**的指纹框架，通过记忆化而非人工触发器-输出过拟合来嵌入所有权信号。这解决了传统后门指纹方法的"隐蔽性-鲁棒性悖论"。

---

#### Two steps:

##### Step 1: Fingerprint Injection（指纹注入阶段）

**数据准备：**
- **指纹数据集** $D_f = D_{tr} \cup D_{ref}$
  - $D_{tr}$：用于指纹嵌入的训练子集（ victim model 训练数据）
  - $D_{ref}$：用于校准成员信号的参考子集
- 关键优势：两个子集来自**相同分布**，避免传统MIA中参考数据集不匹配的问题
- 使用**任意自然语言语料库**（如AG News、XSum），无需人工扰动或显式触发模式

**模型训练：**
- **Victim Model (θ)**：使用 $D_{tr}$ 进行LoRA微调
- **Reference Model (ψ)**：使用 $D_{ref}$ 进行LoRA微调
- 目标函数：标准语言建模目标
  $$\mathcal{L} = -\sum_{x \in D} \sum_{i=1}^{n} \log p(x_i | x_{<i})$$
- 对称微调策略确保两个模型经历等效的优化过程，仅训练子集不同

**关键设计：**
- 避免使用低频词汇、人工触发模式或过拟合
- 保持数据的语义完整性和分布自然性
- 记忆化是LLM实现最优性的固有特性，不会导致过拟合

---

##### Step 2: Probability Variation-based Verification（基于概率变化的验证阶段）

**核心思想：**
验证嫌疑模型 $θ_U$ 是否保留了对 $D_{tr}$ 的潜在记忆。与依赖预定义触发器-响应映射的后门方法不同，EverTracer将验证重构为**检测隐式记忆**。

**理论基础：**
- 成员记录占据模型似然 landscape 中的局部最大值（Mattern et al., 2023）
- 通过估计指纹样本与其邻域记录之间的概率偏移来量化记忆深度

**概率变化（PV）信号计算：**

对于每个指纹样本 $x \in D_{tr}$，生成 $K$ 个语义扰动的邻域样本：
- $x^+_k$：正向语义扰动
- $x^-_k$：负向语义扰动

**概率变化公式：**
$$\tilde{p}_{\theta_U}(x) = \frac{1}{2K} \sum_{k=1}^{K} \left[ p_{\theta_U}(x^+_k) + p_{\theta_U}(x^-_k) \right] - p_{\theta_U}(x)$$

其中：
- $p_{\theta_U}(x)$ 是嫌疑模型分配的对数似然
- 扰动通过随机选择30%的token并使用T5-Base在语义空间进行正负替换生成

**校准信号：**
使用参考模型 $ψ_{ref}$ 计算校准信号以消除分布偏差：
$$\Delta \tilde{p}(x) = \tilde{p}_{\theta_U}(x) - \tilde{p}_{\psi_{ref}}(x)$$

**决策规则：**
给定阈值 $γ$，如果 $\Delta \tilde{p}(x) \geq γ$，则预测该样本被记忆。

---

#### 评估指标

**1. True Positive Rate (TPR)**
$$TPR(γ) = \frac{1}{|D_{tr}|} \sum_{x \in D_{tr}} \mathbb{1}[\Delta \tilde{p}(x) \geq γ]$$
正确识别为记忆的指纹记录比例

**2. False Positive Rate (FPR)**
$$FPR(γ) = \frac{1}{|D_{unseen}|} \sum_{x \in D_{unseen}} \mathbb{1}[\Delta \til{p}(x) \geq γ]$$
非成员记录被错误识别为记忆的比例

**3. Fingerprint Success Rate (FSR)**
在最大阈值 $γ^*$ 下达到的TPR，其中 $FPR(γ^*) \leq 5\%$
- 更高的FSR表示嫌疑模型更可能记忆了注入的指纹数据

**4. AUC (Area Under Curve)**
TPR-FPR曲线下的面积
- 更高的AUC表示成员与非成员之间的可分离性更强

---

#### 方法优势

| 特性 | EverTracer | 传统后门方法 | 优化方法 |
|-----|-----------|------------|---------|
| **隐蔽性** | ✅ 使用自然语言，PPL与正常输入相当 | ⚠️ 低频词汇导致高PPL，易被检测 | ❌ 对抗性提示不自然 |
| **鲁棒性** | ✅ 记忆化对剪枝、合并、增量训练更鲁棒 | ⚠️ 过拟合易被破坏 | ⚠️ 输入扰动敏感 |
| **无需白盒** | ✅ 仅需logits/loss | ❌ 通常需要 | ✅ 仅需API访问 |
| **无触发器** | ✅ 无需预定义触发-响应对 | ❌ 需要 | ✅ 不需要 |
| **灰盒验证** | ✅ 仅需生成文本和logits | ❌ 通常需要白盒 | ✅ 仅需API |

![[截屏2026-02-05 17.51.18.png]]



### About Treat Model：
在LLM的知识产权保护范式中，防御者（模型所有者）和攻击者（恶意行为者）之间存在对抗性动态关系。
攻击者的目标是在绕过所有权验证的同时窃取模型。作者考虑构建一种自适应攻击者，它能够通过两个操作阶段去除嵌入的指纹信息。在部署前阶段，攻击者可以应用模型级转换（例如剪枝非关键参数、在辅助语料库上进行后训练或模型融合）来抑制指纹信号，同时保持任务性能。
在部署阶段，输入时防御措施包括基于困惑度的过滤和对抗性查询扰动，以规避触发激活。在这种情况下，攻击者可能会牺牲一些效用来换取指纹移除。在部署阶段，输入时防御措施包括困惑度。

相比之下，防御者采用通过私有数据记忆进行精细调整的指纹注入。验证在灰盒约束下进行，仅限于生成的文本和相应的logits/loss值，无需内部模型检查。


### 成员推断攻击（MIAs）
**成员推断攻击（Membership Inference Attack, MIA）** 是一种针对机器学习模型的隐私攻击手段。指攻击者试图判断：**某个特定数据样本是否被用于训练目标模型**

#### 攻击原理

机器学习模型对**训练时见过的数据**和**没见过的新数据**往往表现出不同的"自信程度"：

| 情况 | 模型行为 | 攻击结论 |
|------|---------|---------|
| 训练成员（见过） | 置信度高、loss低 | 可能是成员 |
| 非成员（没见过） | 置信度低、loss高 | 可能不是成员 |

#### 攻击流程

1. **准备阶段**：攻击者收集一些与目标模型训练数据相似的样本
2. **训练攻击模型**：用这些样本在其他类似模型上的输出作为特征，训练一个二分类器（成员 vs 非成员）
3. **实施攻击**：将目标样本输入目标模型，观察其输出（预测概率/损失值），通过攻击模型判断是否为训练成员

#### 风险场景

- **医疗AI**：推断某人的病历是否被用于训练疾病诊断模型
- **金融风控**：推断某人的贷款记录是否在银行的风控模型训练集中
- **人脸识别**：推断某张照片是否被用于训练某个人脸识别系统

#### 防御方法

- **差分隐私（Differential Privacy）**：训练时添加噪声，模糊个体影响
- **正则化**：防止模型对训练数据过度拟合
- **知识蒸馏**：用更"平滑"的模型替代原始模型
- **输出扰动**：对模型输出的概率分布进行模糊处理

MIA 是评估机器学习模型隐私泄露风险的重要指标，尤其在处理敏感数据（医疗、金融）时尤为重要。