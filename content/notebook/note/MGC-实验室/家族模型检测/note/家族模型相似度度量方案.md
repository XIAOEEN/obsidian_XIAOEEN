# 模型家族相似度度量方案（Model Family Relationship Metric）

## 研究背景与动机

### 当前挑战

随着开源大语言模型（LLM）的普及和微调技术的成熟（如LoRA、Full Fine-tuning），**私有微调小模型**变得越来越简单。这一趋势对现有的AI生成内容（AIGC）检测生态系统构成了严峻挑战：

1. **检测器失效问题**：目前主流检测器大多基于通用模型（GPT、Claude、Gemini、Grok、DeepSeek）生成文本的训练，当面对海量的、未知的、经过特定领域数据（如金融、医疗）微调的私有模型时，其检测性能显著下降，甚至失效。

2. **监管盲区问题**：这些私有模型游离于大型科技公司的监管体系之外，无法强制实施水印等溯源技术，形成了潜在的监管盲区，为虚假信息、学术不端和恶意滥用等行为提供了温床。

### 核心定义

**家族模型（Model Family）**：所有基于同一尺寸的基座模型（Base Model）通过不同方式（如不同微调数据、不同微调方法）衍生出的模型集合。

例如：
```
LLaMA-2-7B (基座模型)
    ├── 医疗领域微调模型
    ├── 金融领域微调模型
    ├── 代码生成微调模型
    └── 通用对话微调模型
```

---

## 核心概念：模型家族度量关系（Model Family Relationship Metric）

### 核心思想

借鉴《Measuring Human Involvement in AI-Generated Text》中**BERTScore**度量人类参与度的思想，我们将模型间的"血缘关系"量化为**模型行为相似度**。

**关键洞察**：
- 论文中：BERTScore_Recall 度量"prompt中的信息有多少出现在生成文本中"
- 我们的方案：BERTScore_Recall 度量"基座模型的行为特征有多少保留在衍生模型中"

---

## 方法论设计

### 第一步：探针数据集构建（Probe Dataset Construction）

类比论文中的Prompt，我们需要设计能够**激发模型家族特征**的探针样本。

#### 1.1 探针设计原则

**多维度覆盖**：
- **知识维度**：事实性知识、常识推理、专业领域知识
- **能力维度**：文本生成、代码生成、逻辑推理、数学计算
- **风格维度**：语言风格、格式偏好、表达习惯
- **边界维度**：对抗性样本、模糊输入、长上下文

#### 1.2 探针数据集结构

```python
Probe Set P = {
    "knowledge_probes": [      # 知识探针
        "解释量子计算的基本原理",
        "描述光合作用的过程",
        "分析2024年全球经济趋势"
    ],
    "capability_probes": [     # 能力探针
        "编写一个Python函数计算斐波那契数列",
        "将这段中文翻译成法文",
        "总结这篇论文的核心贡献"
    ],
    "style_probes": [          # 风格探针
        "用莎士比亚的风格写一封情书",
        "以学术写作风格描述这个实验",
        "用新闻报道格式撰写这篇文章"
    ],
    "boundary_probes": [       # 边界探针
        "回答一个模棱两可的问题",
        "处理包含矛盾信息的输入",
        "生成长度超过2000 tokens的文本"
    ]
}
```

#### 1.3 探针响应生成

对于每个探针样本，从以下模型生成响应：
- **Reference（参考模型）**：基座模型（Base Model）
- **Candidate（候选模型）**：待检测的衍生模型

```
对于探针 pᵢ:
    Reference Text Rᵢ = BaseModel.generate(pᵢ)
    Candidate Text Cᵢ = CandidateModel.generate(pᵢ)
```

---

### 第二步：BERTScore-based 家族相似度度量

#### 2.1 BERTScore Recall 计算

**核心公式**（借鉴论文公式1）：

$$
\text{Recall}(R, C) = \frac{1}{|R|} \sum_{r_i \in R} \max_{c_j \in C} \cos(\text{BERT}(r_i), \text{BERT}(c_j))
$$

其中：
- $R$：参考模型（基座）生成的文本
- $C$：候选模型（衍生）生成的文本
- $\text{BERT}(\cdot)$：BERT嵌入向量
- $\cos(\cdot, \cdot)$：余弦相似度

**解读**：
- **高Recall** → 候选模型保留了基座模型的大部分行为特征（血缘关系近）
- **低Recall** → 候选模型与基座模型行为差异大（血缘关系远或无关）

#### 2.2 家族关系分数（Family Relationship Score）

对探针集合中的所有样本计算平均Recall：

$$
\text{FRS} = \frac{1}{N} \sum_{i=1}^{N} \text{Recall}(R_i, C_i)
$$

归一化处理（使用max-min归一化）：

$$
y_{family} = \frac{\text{FRS} - \min(\text{FRS})}{\max(\text{FRS}) - \min(\text{FRS})}
$$

最终输出：**0-1之间的连续值**，表示模型间的血缘亲疏程度。

---

### 第三步：可解释性分析（Interpretability Analysis）

类比论文中的Token Classification，我们设计**词汇级血缘分析**。

#### 3.1 文本预处理与标注

**处理流程**：
1. **停用词去除**：去除"的"、"了"、"是"等高频无意义词汇
2. **词形还原（Lemmatization）**：将词汇还原到原型
   - "running" → "run"
   - "better" → "good"
3. **词性标注（POS Tagging）**：识别名词、动词、形容词等

#### 3.2 共同词汇分析

对于每个探针响应对 $(R_i, C_i)$，分析：

**共同词汇占比**：
$$
\text{CommonRatio} = \frac{|\text{Lemmatize}(R_i) \cap \text{Lemmatize}(C_i)|}{|\text{Lemmatize}(R_i)|}
$$

**词性级别分析**：
| 词性类别 | 共同词占比 | 含义解读 |
|---------|-----------|---------|
| **名词（Noun）** | 85% | 知识概念继承度高 |
| **动词（Verb）** | 60% | 行为模式有所变化 |
| **形容词（Adj）** | 45% | 风格偏好明显改变 |
| **专业术语** | 90% | 领域知识保留完整 |

**示例可视化**：
```
探针："解释机器学习"

Reference（基座模型）:
"机器学习是一种人工智能方法，通过数据训练模型..."

Candidate（医疗微调模型）:
"机器学习是一种医疗AI技术，通过患者数据训练诊断模型..."

共同词汇（绿色标注）：
机器学习、是一种、通过、数据、训练、模型

新增词汇（蓝色标注）：
医疗AI技术、患者、诊断

血缘分析：
- 核心概念保留度：85%（高血缘）
- 领域适配度：新增医疗相关词汇（合法微调特征）
```

---

### 第四步：双头检测器设计（Dual-Head Detector）

借鉴论文的双头RoBERTa架构，设计**双头家族检测器**：

#### 4.1 架构设计

```
                    探针响应文本对 (R, C)
                           ↓
              Shared BERT/RoBERTa Encoder
                 (共享编码器)
                           ↓
        ┌──────────────────┼──────────────────┐
        ↓                  ↓                  ↓
   Regression Head    Token/Probe        POS-Level
   (家族血缘度估计)    Classification     Classification
        ↓             (探针分类)           Head
   Family Score          ↓                  ↓
   (0-1连续值)    哪些探针被"继承"      词性级血缘度
```

#### 4.2 回归头（Regression Head）

**目标**：估计候选模型与基座模型的**家族血缘度**

**输入**：
- BERTScore Recall 值
- 词汇重叠度特征
- 语义相似度特征

**输出**：
- 连续值 $y \in [0, 1]$
- 0 = 完全无关
- 1 = 直接复制
- 中间值 = 不同程度微调

**训练目标**：
$$
\mathcal{L}_{MSE} = \frac{1}{N} \sum_{i=1}^{N} (y_{family}^{(i)} - \hat{y}_{family}^{(i)})^2
$$

#### 4.3 探针分类头（Probe Classification Head）

**目标**：识别哪些**探针样本**被候选模型"继承"

**输入**：单个探针的响应特征

**输出**：二分类标签
- 1 = 该探针行为被继承（与基座相似）
- 0 = 该探针行为被改变（与基座不同）

**可解释性**：
- 展示哪些**能力维度**被保留
- 展示哪些**知识领域**被修改

#### 4.4 词性分类头（POS-Level Classification Head）

**目标**：细粒度分析不同词性类别的血缘度

**输入**：词性标注后的词汇序列

**输出**：每个词性的血缘度分数
- 名词血缘度：反映知识继承
- 动词血缘度：反映行为模式
- 形容词血缘度：反映风格偏好

---

### 第五步：连续家族数据集构建

#### 5.1 FT-LLM（Family Tree LLM）数据集

**数据生成策略**：

```
基座模型 LLaMA-2-7B (100%血缘)
    ↓
├── 直接复制模型 (100%血缘)
    ↓ 轻微微调
├── 1 epoch, lr=1e-5 (90%血缘)
├── 3 epoch, lr=1e-5 (80%血缘)
    ↓ 中度微调  
├── LoRA微调, 医疗数据 (60%血缘)
├── LoRA微调, 金融数据 (60%血缘)
    ↓ 深度微调
├── Full Fine-tune, 10 epoch (40%血缘)
├── Full Fine-tune, 20 epoch (20%血缘)
    ↓ 模型合并
├── 与Mistral合并 (10%血缘)
    ↓ 无关模型
└── Mistral-7B, Falcon-7B (0%血缘)
```

#### 5.2 血缘度标注方法

- **100%**：完全相同参数
- **90%**：轻微领域适配（<100 steps）
- **60%**：LoRA微调（标准领域适配）
- **20%**：深度微调（行为大幅改变）
- **0%**：不同架构模型

---

## 应用场景

### 场景1：私有模型识别与监管

**问题**：检测某文本是否来自未知的私有微调模型

**解决方案**：
```
输入：待检测文本
步骤：
1. 使用BERTScore对比基座模型和候选模型的探针响应
2. 计算Family Relationship Score
3. 若FRS > 0.6，判定为家族成员
4. 通过可解释性分析，识别微调领域（医疗/金融/代码）
```

### 场景2：模型血统认证

**问题**：某模型声称是"LLaMA-2微调版本"，验证其真实性

**解决方案**：
```
检测：BERTScore_Recall(LLaMA-2, Suspect) = 0.85
结论：确认为LLaMA-2家族成员，轻微微调
监管建议：符合开源协议，合法使用
```

### 场景3：家族树重建

**问题**：追踪模型的演化历史

**解决方案**：
```
通过连续血缘度估计，构建演化树：
                    LLaMA-2-7B
                   /     |     \
                0.9    0.7     0.5
               /        |        \
          Model A    Model B    Model C
          (医疗)     (金融)     (代码)
```

---

## 技术优势

| 特性 | 传统AIGC检测器 | 本方案 |
|-----|--------------|--------|
| **检测对象** | 通用大模型 | ✅ 支持私有微调模型 |
| **检测粒度** | 二分类（AI/人类） | ✅ 连续血缘度（0-1） |
| **溯源能力** | ❌ 无法溯源 | ✅ 识别祖先模型 |
| **可解释性** | 低（黑盒） | ✅ 词汇级分析 |
| **领域适应** | ❌ 领域数据导致失效 | ✅ 专门设计应对 |

---

## 实验设计建议

### 基座模型选择
- LLaMA-2-7B/13B
- Mistral-7B
- Qwen-7B
- Falcon-7B

### 衍生模型生成
- **不同微调数据**：医疗、金融、法律、代码、教育
- **不同微调方法**：LoRA、QLoRA、Adapter、Full Fine-tune
- **不同微调强度**：1/5/10/20 epochs，不同学习率
- **模型合并**：MergeKit生成的融合模型

### 评估指标
- **MSE**：血缘度估计误差
- **Spearman ρ**：与真实血缘度的相关性
- **AUC-ROC**：家族成员分类准确率
- **可解释性准确率**：词汇级分析准确率

---

## 未来工作

1. **跨架构血缘追踪**：探索不同架构模型（如Transformer vs RNN）间的血缘关系
2. **动态血缘监测**：持续监测模型在部署后的行为漂移
3. **水印与血缘结合**：结合传统水印技术与行为相似度，构建更鲁棒的溯源体系
4. **监管框架集成**：将本方案集成到实际的AIGC检测平台中

---

## 核心公式总结

**BERTScore Recall（家族相似度）**：
$$
\text{Recall}(R, C) = \frac{1}{|R|} \sum_{r_i \in R} \max_{c_j \in C} \cos(\text{BERT}(r_i), \text{BERT}(c_j))
$$

**家族关系分数**：
$$
y_{family} = \frac{\text{FRS} - \min(\text{FRS})}{\max(\text{FRS}) - \min(\text{FRS})}
$$

**共同词汇占比**：
$$
\text{CommonRatio} = \frac{|\text{Lemmatize}(R) \cap \text{Lemmatize}(C)|}{|\text{Lemmatize}(R)|}
$$

---

*本方案借鉴了《Measuring Human Involvement in AI-Generated Text》中BERTScore度量人类参与度的核心思想，将其迁移至模型家族血缘度量领域。*
